{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 0.5],\n",
       "       [0.5, 1. ]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef([1, 2, 3], [0, 1, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'dni' from '/home/zh2408/dni.py'>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dni\n",
    "import importlib\n",
    "importlib.reload(dni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hi():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros(shape=(5,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'hi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-2644b9babe1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'hi'"
     ]
    }
   ],
   "source": [
    "a[1,1,1] = hi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricManager():\n",
    "    def __init__(self, listofmetrics):\n",
    "        import numpy as np\n",
    "        self.metrics = listofmetrics\n",
    "    # input should from one layer one unit\n",
    "    def increment(self,input1,input2):\n",
    "        for i in range(len(input1)):\n",
    "            self.sumXsquare += input1[i]**2\n",
    "            self.sumYsquare += input2[i]**2\n",
    "            self.sumX += input1[i]\n",
    "            self.sumY += input2[i]\n",
    "            self.sumXY += input1[i]*input2[i]\n",
    "            self.n += 1\n",
    "    def extract(self):\n",
    "        return (self.sumXY - self.sumX*self.sumY/self.n)/(((self.sumXsquare - self.sumX**2/self.n)**(1/2))*((self.sumYsquare - self.sumY**2/self.n)**(1/2)))\n",
    "    def get_class(self):\n",
    "        return \"Batch_incremental_Correlation\"\n",
    "    def get_name(self):\n",
    "        return \"Correlation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch mode exhaustive correlation\n",
    "class Batch_Incremental_Comprehensive_Correlation():\n",
    "    def __init__(self, model, layer, unit, feature):\n",
    "        import numpy as np\n",
    "        self.sumXsquare = np.zeros(shape=(model, layer, unit, feature))\n",
    "        self.sumYsquare = np.zeros(shape=(model, layer, unit, feature))\n",
    "        self.sumX = np.zeros(shape=(model, layer, unit, feature))\n",
    "        self.sumY = np.zeros(shape=(model, layer, unit, feature))\n",
    "        self.sumXY = np.zeros(shape=(model, layer, unit, feature))\n",
    "        self.n = np.full((model, layer, unit, feature),1e-17)\n",
    "    # input should from one layer one unit\n",
    "    def increment(self,input1,input2,model, layer, unit, feature):\n",
    "        import numpy as np\n",
    "        while input1.ndim != 1:\n",
    "            input1 = np.concatenate(input1)\n",
    "        while input2.ndim != 1:\n",
    "            input2 = np.concatenate(input2)\n",
    "        for i in range(len(input1)):\n",
    "            self.sumXsquare[model, layer, unit, feature] += input1[i]**2\n",
    "            self.sumYsquare[model, layer, unit, feature] += input2[i]**2\n",
    "            self.sumX[model, layer, unit, feature] += input1[i]\n",
    "            self.sumY[model, layer, unit, feature] += input2[i]\n",
    "            self.sumXY[model, layer, unit, feature] += input1[i]*input2[i]\n",
    "            self.n += 1\n",
    "    def extract(self,model, layer, unit, feature):\n",
    "        return (self.sumXY[model, layer, unit, feature] - self.sumX[model, layer, unit, feature]*self.sumY[model, layer, unit, feature]/\\\n",
    "                self.n[model, layer, unit, feature])/(((self.sumXsquare[model, layer, unit, feature] - self.sumX[model, layer, unit, feature]\\\n",
    "                **2/self.n[model, layer, unit, feature])**(1/2))*((self.sumYsquare[model, layer, unit, feature]\\\n",
    "                - self.sumY[model, layer, unit, feature]**2/self.n[model, layer, unit, feature])**(1/2))+1e-17)\n",
    "    def get_class(self):\n",
    "        return \"Batch_Incremental_Comprehensive_Correlation\"\n",
    "    def get_name(self):\n",
    "        return \"Correlation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = Batch_Incremental_Comprehensive_Correlation(1,2,2,2)\n",
    "b.extract(0,0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b.increment([1, 2, 3], [0, 1, 0.5])\n",
    "\n",
    "b.increment([1, 2], [0, 1],0,1,0,0)\n",
    "# b.increment([3], [0.5],0,0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.extract(0,1,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[10, 10],\n",
       "        [10, 10]],\n",
       "\n",
       "       [[10, 10],\n",
       "        [10, 10]]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.full((2,2, 2), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 **(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-17"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0/1e-17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tryy():\n",
    "    id = 0\n",
    "    def __init__(self):\n",
    "        self.p = None\n",
    "        self.id = tryy.id\n",
    "        tryy.id += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt=tryy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tryy.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Op(object):\n",
    "    \"\"\"\n",
    "    Base class\n",
    "    all operators have a single parent\n",
    "    an operator may have multiple children\n",
    "    \"\"\"\n",
    "    _id = 0\n",
    "    def __init__(self):\n",
    "        self.p = None\n",
    "        self.id = Op._id\n",
    "        Op._id += 1\n",
    "    def __hash__(self):\n",
    "        return self.id\n",
    "    def __eq__(self, o):\n",
    "        return o and hash(self) == hash(o)\n",
    "    def replace(self, newop):\n",
    "        \"\"\"\n",
    "        Replace myself with @newop in the tree.\n",
    "        The key is to reassign the parent and child pointers appropriately.\n",
    "        \"\"\"\n",
    "        if not self.p: return\n",
    "        p = self.p\n",
    "        newop.p = p\n",
    "        if isinstance(p, UnaryOp):\n",
    "            p.c = newop\n",
    "        if isinstance(p, BinaryOp):\n",
    "            if p.l == self:\n",
    "                p.l = newop\n",
    "            elif p.r == self:\n",
    "                p.r = newop\n",
    "        if isinstance(p, NaryOp):\n",
    "            if self in p.cs:\n",
    "                cs[cs.index(self)] = newop\n",
    "            p.cs = cs\n",
    "    def is_ancestor(self, anc):\n",
    "        \"\"\"\n",
    "        Check if @anc is an ancestor of the current operator\n",
    "        \"\"\"\n",
    "        n = self\n",
    "        seen = set()\n",
    "        while n and n not in seen:\n",
    "            seen.add(n)\n",
    "            if n == anc:\n",
    "                return True\n",
    "            n = n.p\n",
    "        return False\n",
    "    def children(self):\n",
    "        \"\"\"\n",
    "        return child operators that are relational operations (as opposed to Expressions)\n",
    "        \"\"\"\n",
    "        children = []\n",
    "        if self.is_type(UnaryOp):\n",
    "            children = [self.c]\n",
    "        if self.is_type(BinaryOp):\n",
    "            children = [self.l, self.r]\n",
    "        if self.is_type(NaryOp):\n",
    "            children = list(self.cs)\n",
    "        return filter(bool, children)\n",
    "    def referenced_op_children(self):\n",
    "        \"\"\"\n",
    "        return all Op subclasses referenced by current operator\n",
    "        \"\"\"\n",
    "        children = []\n",
    "        for key, attrval in self.__dict__.items():\n",
    "            if key in [\"p\"]:   # avoid following cycles\n",
    "                continue\n",
    "        if not isinstance(attrval, list):\n",
    "            attrval = [attrval]\n",
    "        for v in attrval:\n",
    "            if v and isinstance(v, Op):\n",
    "                  children.append(v)\n",
    "        return children\n",
    "    def traverse(self, f, path=None):\n",
    "        \"\"\"\n",
    "        Visit all referenced Op subclasses and call f()\n",
    "        @f a function that takes as input the current operator and \n",
    "        the path to the operator.  f() can return False to\n",
    "        stop traversing subplans.\n",
    "        \"\"\"\n",
    "        if path is None:\n",
    "            path = []\n",
    "        path = path + [self]\n",
    "        if f(self, path) == False:\n",
    "            return\n",
    "        for child in self.referenced_op_children():\n",
    "            child.traverse(f, path)\n",
    "    def is_type(self, klass_or_names):\n",
    "        \"\"\"\n",
    "        Check whether self is a subclass of argument\n",
    "        @klass_or_names an individual or list of classes\n",
    "        \"\"\"\n",
    "        if not isinstance(klass_or_names, list):\n",
    "            klass_or_names = [klass_or_names]\n",
    "        names = [kn for kn in klass_or_names if isinstance(kn, str)]\n",
    "        klasses = [kn for kn in klass_or_names if isinstance(kn, type)]\n",
    "        return (self.__class__.__name__ in names or\n",
    "           any([isinstance(self, kn) for kn in klasses]))\n",
    "    def collect(self, klass_or_names):\n",
    "        \"\"\"\n",
    "        Returns all operators in the subplan rooted at the current object\n",
    "        that has the same class name, or is a subclass, as the arguments\n",
    "        \"\"\"\n",
    "        ret = []\n",
    "        if not isinstance(klass_or_names, list):\n",
    "            klass_or_names = [klass_or_names]\n",
    "        names = [kn for kn in klass_or_names if isinstance(kn, str)]\n",
    "        klasses = [kn for kn in klass_or_names if isinstance(kn, type)]\n",
    "\n",
    "        def f(node, path):\n",
    "            if node and (\n",
    "              node.__class__.__name__ in names or\n",
    "              any([isinstance(node, kn) for kn in klasses])):\n",
    "                ret.append(node)\n",
    "        self.traverse(f)\n",
    "        return ret\n",
    "    def collectone(self, klassnames):\n",
    "        \"\"\"\n",
    "        Helper function to return an arbitrary operator that matches any of the\n",
    "        klass names or klass objects, or None\n",
    "        \"\"\"\n",
    "        l = self.collect(klassnames)\n",
    "        if l:\n",
    "            return l[0]\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = UnaryOp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dictionary1 = {tuple([1,2]): 'Geeks', 'B': 'For', 'C': 'Geeks'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Geeks'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dictionary1[tuple([1,2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, None, 3)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple([1,None,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "registry = UDFRegistry.registry()\n",
    "registry.add(np.mean,\"avg\")\n",
    "udf = registry[\"avg\"]\n",
    "udf([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HighDimensionPartitionableTable():\n",
    "    def __init__(self, table=None, padding = 0):\n",
    "        # table is a an nparray\n",
    "        # 1. input_id 2. model_id 3. layer_id 4. unit_id 5. feature_id 6. feature/activation\n",
    "        self.table = table\n",
    "        # after partition, all the index are zero-based\n",
    "        # use padding to track the real input_id\n",
    "        self.padding = padding\n",
    "    # iterate through specified number of dimensions\n",
    "    # for now only support 5 dimensions\n",
    "    def itr(self, dimension = 5):\n",
    "        for i in range(len(self.table)):\n",
    "            for j in range(len(self.table[i])):\n",
    "                for k in range(len(self.table[i][j])):\n",
    "                    for l in range(len(self.table[i][j][k])):\n",
    "                        for m in range(len(self.table[i][j][k][l])):\n",
    "                            yield [i + self.padding,j,k,l,m], self.table[i][j][k][l][m]\n",
    "    # partition HighDimensionPartitionableTable\n",
    "    # and returns two HighDimensionPartitionableTables\n",
    "    def partition(self, partition_num):\n",
    "        total_num = len(self.table)\n",
    "        step = total_num//partition_num\n",
    "        Tables = []\n",
    "        for i in range(partition_num - 1):\n",
    "            Tables.append(HighDimensionPartitionableTable(self.table[i*step:(i+1)*step],i*step))\n",
    "        Tables.append(HighDimensionPartitionableTable(self.table[(partition_num - 1)*step:],(partition_num - 1)*step))\n",
    "        return Tables\n",
    "    def get_stat(self):\n",
    "        if self.table is None:\n",
    "            return \"not initialized\"\n",
    "        return {\"feature_num\":self.feature_num, \"input_num\":self.input_num, \"feature_shape\": self.feature_shape}\n",
    "    def merge(self, table):\n",
    "        if self.table is None:\n",
    "            self.table = table\n",
    "        else:\n",
    "            self.table = self.table + table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = a +[4]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = HighDimensionPartitionableTable([[[[[0]]]],[[[[1]]]],[[[[5]]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.merge([[[[[7]]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = P.itr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0] 0\n",
      "[1, 0, 0, 0, 0] 1\n",
      "[2, 0, 0, 0, 0] 5\n",
      "[3, 0, 0, 0, 0] 7\n"
     ]
    }
   ],
   "source": [
    "for i,j in it:\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = P.partition(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0, 0, 0, 0, 0] 0\n",
      "1 [1, 0, 0, 0, 0] 1\n",
      "2 [2, 0, 0, 0, 0] 5\n",
      "2 [3, 0, 0, 0, 0] 7\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(a)):\n",
    "    it = a[i].itr()\n",
    "    for j,k in it:\n",
    "        print(i,j,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class AbsFeatureExtractor():\n",
    "    def __init__(self):\n",
    "        self.num = [1,2,3,4]\n",
    "        self.curr = 0\n",
    "    def get_next(self):\n",
    "        self.curr += 1\n",
    "        return self.num[self.curr - 1]\n",
    "    # has_next\n",
    "    # implemented in abstract\n",
    "    def have_next(self):\n",
    "        pass\n",
    "    def extract(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class getter():\n",
    "    def __init__(self,c):\n",
    "        self.c = c\n",
    "    def get_next(self):\n",
    "        return ray.get(self.c.get_next.remote())\n",
    "    # has_next\n",
    "    # implemented in abstract\n",
    "    def have_next(self):\n",
    "        pass\n",
    "    def extract(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =  AbsFeatureExtractor.remote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = getter.remote(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-24 22:23:28,030\tWARNING worker.py:1268 -- WARNING: Not updating worker name since `setproctitle` is not installed. Install this with `pip install setproctitle` (or ray[debug]) to enable monitoring of worker processes.\n",
      "2019-11-24 22:23:28,036\tINFO resource_spec.py:205 -- Starting Ray with 7.81 GiB memory available for workers and up to 3.92 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '10.128.0.51',\n",
       " 'object_store_address': '/tmp/ray/session_2019-11-24_22-23-28_033785_12487/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2019-11-24_22-23-28_033785_12487/sockets/raylet',\n",
       " 'redis_address': '10.128.0.51:20342',\n",
       " 'session_dir': '/tmp/ray/session_2019-11-24_22-23-28_033785_12487',\n",
       " 'webui_url': None}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[[[5]]]]]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[[[[0]]]],[[[[1]]]],[[[[5]]]]][2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator2():\n",
    "    for i in range(10):\n",
    "        yield i\n",
    "\n",
    "def generator3():\n",
    "    for j in range(10, 20):\n",
    "        yield j\n",
    "\n",
    "def generator():\n",
    "    for i in generator2():\n",
    "        yield i\n",
    "    for j in generator3():\n",
    "        yield j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "for i in k:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'itertools' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-ccf11c6c6261>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'itertools' is not defined"
     ]
    }
   ],
   "source": [
    "itertools.product()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
